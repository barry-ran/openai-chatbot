import openai
import streamlit as st
from streamlit_chat import message

# streamlitæ²¡æœ‰å›è°ƒå‡½æ•°æœºåˆ¶ï¼Œæ¯æ¬¡ç”¨æˆ·äº¤äº’éƒ½ä¼šä»å¤´åˆ°å°¾æ‰§è¡Œä¸€éapp.pyä»£ç 
# æ‰€ä»¥éœ€è¦ç”¨session_stateæ¥ä¿å­˜ä¸Šä¸€æ¬¡çš„äº¤äº’ç»“æœ

# openai api
#openai.api_key = st.secrets['api_secret']
def generate_response(prompt):
    pre_prompt = [        
        {"role": "system", "content": "You are a helpful assistant."}
    ]
    pre_prompt.extend(prompt)
    completions = openai.ChatCompletion.create(
        model="gpt-3.5-turbo",
        messages=pre_prompt,
        temperature=0.7,
    )
    
    message = completions.choices[0].message.content
    return message

# æµ‹è¯•cache(å…¨å±€ç¼“å­˜ï¼Œå’Œä¼šè¯æ— å…³ï¼Œæ— è®ºä¼šè¯åˆ·æ–°å¤šå°‘æ¬¡ï¼Œåªè¦å‚æ•°ä¸å˜ï¼Œè¿”å›å€¼ä¸å˜ï¼Œéƒ½æ˜¯ä¸ä¼šé‡å¤æ‰§è¡Œ)
# https://docs.streamlit.io/library/advanced-features/caching
@st.cache_data
def test_cache(p1):
    print("***********test cache***********")
    return p1

test_cache("test")

# æµ‹è¯•session_state(ä¼šè¯ç¼“å­˜ï¼Œå’Œä¼šè¯ç›¸å…³)
# æ™®é€šç”¨æˆ·äº¤äº’å¯¼è‡´çš„rerunä¸ä¼šæ¸…ç©ºsession_stateï¼Œåªæœ‰æµè§ˆå™¨åˆ·æ–°æˆ–è€…æ–°tabæ‰“å¼€ç½‘é¡µæ‰ä¼šæ¸…ç©º
# https://docs.streamlit.io/library/api-reference/session-state
if 'test_session_state' not in st.session_state:
    print("not in session_state")
    st.session_state['test_session_state'] = "data"
else:
    print("session_state")    

# ç¼“å­˜
if 'ai_assistant' not in st.session_state:
    st.session_state['ai_assistant'] = []

if 'user' not in st.session_state:
    st.session_state['user'] = []

if 'chat_history' not in st.session_state:
    st.session_state['chat_history'] = []

if 'cur_input' not in st.session_state:
    st.session_state['cur_input'] = ""

# å¼€å§‹å¸ƒå±€UI
st.title("ğŸ¤– chatBot : openAI GPT-3 + Streamlit")

openai.api_key = st.text_input("input openai api key: ","")    

# streamlitæ˜¯é¡ºåºæ‰§è¡Œè¿‡ç¨‹è¾¹æ‰§è¡Œè¾¹æ˜¾ç¤º
# ä»£ç é€»è¾‘è‚¯å®šæ˜¯å…ˆæ‰§è¡Œrecvè·å–ç”¨æˆ·è¾“å…¥ï¼Œå†æ‰§è¡Œshowæ˜¾ç¤ºç»“æœï¼Œè¿™æ ·å°±å…ˆæ˜¾ç¤ºrecvå†æ˜¾ç¤ºshow
# ä½†æ˜¯æˆ‘æƒ³showæ˜¾ç¤ºåœ¨ä¸Šé¢ï¼Œrecvæ˜¾ç¤ºåœ¨ä¸‹é¢ï¼Œæ‰€ä»¥è¦ç”¨containeræ¥å®ç°è¡Œå¸ƒå±€ï¼Œè°ƒæ•´recvå’Œshowçš„é¡ºåº
# è¡¥å……ï¼šä½¿ç”¨st.empty()å ä½ä¹Ÿå¯ä»¥å®ç°ä¹±åºæ’å…¥å…ƒç´ çš„æ•ˆæœ https://docs.streamlit.io/knowledge-base/using-streamlit/insert-elements-out-of-order
show_container = st.container()
recv_container = st.container()

# æ¥æ”¶ç”¨æˆ·è¾“å…¥åŒºåŸŸ
with recv_container:
    def input_update():
        # è·å–è¾“å…¥å¹¶æ¸…ç©ºè¾“å…¥æ¡†
        st.session_state.cur_input = st.session_state.input        
        st.session_state.input = " "
    
    # åªæœ‰ç¬¬ä¸€æ¬¡è¿è¡Œè¿”å›é»˜è®¤å€¼ï¼Œåé¢çš„è¿è¡Œè¿”å›ç”¨æˆ·è¾“å…¥çš„å†…å®¹
    st.text_input("input your question: ", "", key="input", on_change=input_update)

print("cur_input: ", st.session_state['cur_input'])

# ç”Ÿæˆå¹¶ä¿å­˜èŠå¤©è®°å½• 
if st.session_state.cur_input:    
    message_request = st.session_state.chat_history
    message_request.append({"role": "user", "content": st.session_state.cur_input})

    print("generate response begin")
    output = generate_response(message_request)
    print("generate response end")
    st.session_state.user.append(st.session_state.cur_input)
    st.session_state.ai_assistant.append(output)

    st.session_state.chat_history.append({"role": "user", "content": st.session_state.cur_input})
    st.session_state.chat_history.append({"role": "assistant", "content": output})

    if len(st.session_state.chat_history) > 10:
        st.session_state.chat_history = st.session_state.chat_history[-10:]
    
    st.session_state['cur_input'] = ""

# èŠå¤©è®°å½•æ˜¾ç¤ºåŒºåŸŸ
with show_container:
    if st.session_state['ai_assistant']:
        for i in range(0, len(st.session_state['ai_assistant'])):
            message(st.session_state['user'][i], is_user=True, key=str(i) + '_user')
            message(st.session_state["ai_assistant"][i], key=str(i) + '_ai_assistant')

